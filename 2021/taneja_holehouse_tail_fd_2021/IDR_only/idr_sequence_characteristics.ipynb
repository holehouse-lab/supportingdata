{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SHEPHARD version: v0.1.2.1+4.g1b3893a\n"
     ]
    }
   ],
   "source": [
    "import shephard\n",
    "import numpy as np \n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(\"Running SHEPHARD version: %s\" %(shephard.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_proteome = './Input_Data/human_proteome_2019_10_clean_no_comma.fasta'\n",
    "human_idrs  = './Input_Data/DISORDER_R3_human_proteome_2019_10_clean_no_comma_shephard_domains.tsv'\n",
    "human_tails_w_pdb = './Input_Data/tails_shephard_metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shephard.apis import uniprot\n",
    "from shephard.interfaces import si_domains\n",
    "\n",
    "proteome = uniprot.uniprot_fasta_to_proteome(human_proteome)\n",
    "si_domains.add_domains_from_file(proteome, human_tails_w_pdb)\n",
    "si_domains.add_domains_from_file(proteome, human_idrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDRs = {}\n",
    "IDRs['all'] = []\n",
    "IDRs['non_tail'] = []\n",
    "IDRs['N'] = []\n",
    "IDRs['C'] = []\n",
    "IDRs['N_w_pdb'] = []\n",
    "IDRs['C_w_pdb'] = []\n",
    "\n",
    "FDs = {}\n",
    "FDs['all'] = []\n",
    "\n",
    "for protein in proteome:\n",
    "    #print(protein)\n",
    "    sequence_len = len(protein.sequence)\n",
    "    \n",
    "    uniprot_id = protein.unique_ID\n",
    "    \n",
    "    for domain in protein.domains:\n",
    "        \n",
    "        idr_len = len(domain.sequence)\n",
    "                \n",
    "        if domain.domain_type == 'IDR':\n",
    "            \n",
    "            # if we find an IDR that starts at residue 1 and is not the same \n",
    "            # size of the protein it must be an N-terminal tail...\n",
    "            if domain.start == 1:\n",
    "                if len(domain) < len(protein):\n",
    "                    IDRs['N'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "            # if we find an IDR that ends at the end of the protein and is not the\n",
    "            # same size as the protein, it must be a C-terminal tail\n",
    "            elif domain.end == len(protein):\n",
    "                if len(domain) < len(protein):\n",
    "                    IDRs['C'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "            elif len(domain) < len(protein):\n",
    "                IDRs['non_tail'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "                \n",
    "            if len(domain) < len(protein):\n",
    "                IDRs['all'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "                \n",
    "        elif domain.domain_type == 'Tail_w_PDB':\n",
    "            #print('here')\n",
    "            #print(domain.attributes)\n",
    "            tail_nterm_status = int(domain.attribute('N_Terminal_Status'))\n",
    "            tail_cterm_status = int(domain.attribute('C_Terminal_Status'))\n",
    "            \n",
    "            if tail_nterm_status == 1:\n",
    "                IDRs['N_w_pdb'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "            elif tail_cterm_status == 1:\n",
    "                IDRs['C_w_pdb'].append([domain.sequence, sequence_len, protein.sequence, uniprot_id])\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of IDRs: 34095\n",
      "Total number of N-terminal IDRs: 5549\n",
      "Total number of C-terminal IDRs: 5705\n",
      "Total number of Non-tails: 22841\n",
      "Total number of N-terminal IDRs w PDB: 326\n",
      "Total number of C-terminal IDRs w PDB: 293\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of IDRs: %i\" %(len(IDRs['all'])))\n",
    "print(\"Total number of N-terminal IDRs: %i\" %(len(IDRs['N'])))\n",
    "print(\"Total number of C-terminal IDRs: %i\" %(len(IDRs['C'])))\n",
    "print(\"Total number of Non-tails: %i\" %(len(IDRs['non_tail'])))\n",
    "print(\"Total number of N-terminal IDRs w PDB: %i\" %(len(IDRs['N_w_pdb'])))\n",
    "print(\"Total number of C-terminal IDRs w PDB: %i\" %(len(IDRs['C_w_pdb'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the all set\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "On the non_tail set\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "On the N set\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "On the C set\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "On the N_w_pdb set\n",
      "0\n",
      "On the C_w_pdb set\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from localcider.sequenceParameters import SequenceParameters\n",
    "\n",
    "# define the three names we're using\n",
    "IDR_types = IDRs.keys()\n",
    "\n",
    "# create empty directionaries for the parameters we're interested in\n",
    "FCR = {}\n",
    "NCPR = {}\n",
    "FP = {} \n",
    "FN = {}\n",
    "kappa = {} \n",
    "phospho = {}\n",
    "IDR_len = {}\n",
    "IDR_Sequence_len_ratio = {} \n",
    "hydropathy = {}\n",
    "hydrophobicity = {}\n",
    "aromaticity = {}\n",
    "protein_charge = {} \n",
    "uniprot_id = {}\n",
    "\n",
    "## Initialize empty lists into each dictionary\n",
    "for n in IDR_types:\n",
    "    FCR[n] = []\n",
    "    NCPR[n] = []\n",
    "    FP[n] = []\n",
    "    FN[n] = []\n",
    "    kappa[n] = []\n",
    "    phospho[n] = []\n",
    "    IDR_len[n] = []\n",
    "    IDR_Sequence_len_ratio[n] = []\n",
    "    hydropathy[n] = []\n",
    "    hydrophobicity[n] = []\n",
    "    aromaticity[n] = []\n",
    "    protein_charge[n] = []\n",
    "    uniprot_id[n] = []\n",
    "\n",
    "\n",
    "# for each dataset\n",
    "for key in IDR_types:\n",
    "    print('On the %s set'%(key))\n",
    "    \n",
    "    # scan over each IDR and compute parameters\n",
    "    for idx,val in enumerate(IDRs[key]):\n",
    "        if (idx % 1000) == 0:\n",
    "            print(idx)\n",
    "        idr = val[0]\n",
    "        sequence_len = val[1]\n",
    "        protein_sequence = val[2]\n",
    "        uniprot_id_val = val[3]\n",
    "        \n",
    "        SO = SequenceParameters(idr)\n",
    "        \n",
    "        FCR[key].append(SO.get_FCR()) \n",
    "        NCPR[key].append(SO.get_NCPR()) \n",
    "        FP[key].append(SO.get_fraction_positive())\n",
    "        FN[key].append(SO.get_fraction_negative())\n",
    "        kappa[key].append(SO.get_kappa())\n",
    "        phospho[key].append(float(len(SO.get_all_phosphorylatable_sites()))/float(SO.get_length()))\n",
    "        IDR_len[key].append(SO.get_length())\n",
    "        IDR_Sequence_len_ratio[key].append(SO.get_length()/sequence_len)\n",
    "        hydropathy[key].append(SO.get_mean_hydropathy())\n",
    "        amino_acid_fraction = SO.get_amino_acid_fractions()\n",
    "        hydrophobic_fraction = amino_acid_fraction['A'] + amino_acid_fraction['V'] + amino_acid_fraction['I'] + amino_acid_fraction['L'] + amino_acid_fraction['M']   \n",
    "        hydrophobicity[key].append(hydrophobic_fraction)\n",
    "        aromatic_fraction = amino_acid_fraction['F'] + amino_acid_fraction['W'] + amino_acid_fraction['Y']\n",
    "        aromaticity[key].append(aromatic_fraction)\n",
    "        #the following lines aren't used for the paper analysis\n",
    "        \n",
    "        #SO_p = SequenceParameters(protein_sequence)\n",
    "        #protein_charge[key].append(SO_p.get_countPos() - SO_p.get_countNeg())\n",
    "        \n",
    "        #uniprot_id[key].append(uniprot_id_val)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcr_df=pd.DataFrame.from_dict(FCR,orient='index').transpose()\n",
    "ncpr_df=pd.DataFrame.from_dict(NCPR,orient='index').transpose()\n",
    "fp_df=pd.DataFrame.from_dict(FP,orient='index').transpose()\n",
    "fn_df=pd.DataFrame.from_dict(FN,orient='index').transpose()\n",
    "kappa_df=pd.DataFrame.from_dict(kappa,orient='index').transpose()\n",
    "phospho_df=pd.DataFrame.from_dict(phospho,orient='index').transpose()\n",
    "hydropathy_df=pd.DataFrame.from_dict(hydropathy,orient='index').transpose()\n",
    "hydrophobicity_df=pd.DataFrame.from_dict(hydrophobicity,orient='index').transpose()\n",
    "aromaticity_df=pd.DataFrame.from_dict(aromaticity,orient='index').transpose()\n",
    "idr_len_df=pd.DataFrame.from_dict(IDR_len,orient='index').transpose()\n",
    "idr_len_sequence_len_df=pd.DataFrame.from_dict(IDR_Sequence_len_ratio,orient='index').transpose()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Output_Data/%s' \n",
    "\n",
    "fcr_df.to_csv(save_path % 'fcr.csv', index=False)\n",
    "ncpr_df.to_csv(save_path % 'ncpr.csv', index=False)\n",
    "fp_df.to_csv(save_path % 'fp.csv', index=False)\n",
    "fn_df.to_csv(save_path % 'fn.csv', index=False)\n",
    "kappa_df.to_csv(save_path % 'kappa.csv', index=False)\n",
    "phospho_df.to_csv(save_path % 'phospho.csv', index=False)\n",
    "idr_len_df.to_csv(save_path % 'idr_len.csv', index=False)\n",
    "idr_len_sequence_len_df.to_csv(save_path % 'idr_len_sequence_len.csv', index=False)\n",
    "\n",
    "hydropathy_df.to_csv(save_path % 'hydropathy.csv', index=False)\n",
    "hydrophobicity_df.to_csv(save_path % 'hydrophobicity.csv', index=False)\n",
    "aromaticity_df.to_csv(save_path % 'aromaticity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the following are not relevant for the analysis in the paper. They were just some additional statistics I calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_charge_df=pd.DataFrame.from_dict(protein_charge,orient='index').transpose()\n",
    "protein_charge_df.to_csv(save_path % 'protein_charge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Output_Data/%s' \n",
    "uniprot_id_df=pd.DataFrame.from_dict(uniprot_id,orient='index').transpose()\n",
    "uniprot_id_df.to_csv(save_path % 'uniprot_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the N_w_pdb set\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "On the C_w_pdb set\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "##for N and C w pdb, calculate cider parameters sliding window##\n",
    "\n",
    "\n",
    "# create empty directionaries for the parameters we're interested in\n",
    "FCR_window = {}\n",
    "NCPR_window = {}\n",
    "hydro_window = {}\n",
    "uniprot_id_window = {}\n",
    "idr_len_window = {}\n",
    "\n",
    "## Initialize empty lists into each dictionary\n",
    "for n in ['N_w_pdb', 'C_w_pdb']:\n",
    "    FCR_window[n] = []\n",
    "    NCPR_window[n] = []\n",
    "    hydro_window[n] = []\n",
    "    uniprot_id_window[n] = []\n",
    "    idr_len_window[n] = []\n",
    "\n",
    "\n",
    "# for each dataset\n",
    "for key in ['N_w_pdb', 'C_w_pdb']:\n",
    "    print('On the %s set'%(key))\n",
    "    \n",
    "    # scan over each IDR and compute parameters\n",
    "    for idx,val in enumerate(IDRs[key]):\n",
    "        \n",
    "        if (idx % 10) == 0:\n",
    "            print(idx)\n",
    "            \n",
    "        idr = val[0]\n",
    "        sequence_len = val[1]\n",
    "        protein_sequence = val[2]\n",
    "        uniprot_id_val = val[3]\n",
    "        \n",
    "        if key == 'C_w_pdb':\n",
    "            for str_idx in range(1,len(idr)):\n",
    "\n",
    "                idr_subset = idr[0:str_idx]\n",
    "\n",
    "                SO = SequenceParameters(idr_subset)\n",
    "\n",
    "                FCR_window[key].append(SO.get_FCR()) \n",
    "                NCPR_window[key].append(SO.get_NCPR()) \n",
    "                hydro_window[key].append(SO.get_mean_hydropathy()) \n",
    "                uniprot_id_window[key].append(uniprot_id_val)\n",
    "                idr_len_window[key].append(len(idr_subset))\n",
    "        else:\n",
    "            \n",
    "            for str_idx in range(len(idr)-1,0,-1):\n",
    "\n",
    "                idr_subset = idr[str_idx:len(idr)]\n",
    "\n",
    "                SO = SequenceParameters(idr_subset)\n",
    "\n",
    "                FCR_window[key].append(SO.get_FCR()) \n",
    "                NCPR_window[key].append(SO.get_NCPR()) \n",
    "                hydro_window[key].append(SO.get_mean_hydropathy()) \n",
    "                uniprot_id_window[key].append(uniprot_id_val)\n",
    "                idr_len_window[key].append(len(idr_subset))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcr_window_df = pd.DataFrame.from_dict(FCR_window,orient='index').transpose()\n",
    "ncpr_window_df = pd.DataFrame.from_dict(NCPR_window,orient='index').transpose()\n",
    "hydro_window_df = pd.DataFrame.from_dict(hydro_window,orient='index').transpose()\n",
    "uniprot_id_window_df = pd.DataFrame.from_dict(uniprot_id_window,orient='index').transpose()\n",
    "idr_len_window_df = pd.DataFrame.from_dict(idr_len_window,orient='index').transpose()\n",
    "\n",
    "\n",
    "save_path = './Output_Data/Window/%s' \n",
    "fcr_window_df.to_csv(save_path % 'fcr_window.csv', index=False)\n",
    "ncpr_window_df.to_csv(save_path % 'ncpr_window.csv', index=False)\n",
    "hydro_window_df.to_csv(save_path % 'hydro_window.csv', index=False)\n",
    "uniprot_id_window_df.to_csv(save_path % 'uniprot_id_window.csv', index=False)\n",
    "idr_len_window_df.to_csv(save_path % 'idr_len_window.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
