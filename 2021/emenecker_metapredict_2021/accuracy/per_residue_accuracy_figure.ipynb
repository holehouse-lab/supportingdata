{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11315867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\t\n",
    "# Set such that PDF fonts export in a manner that they\n",
    "# are editable in illustrator/affinity\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# set to define axes linewidths\n",
    "matplotlib.rcParams['axes.linewidth'] = 0.5\n",
    "\n",
    "# this defines some prefactors so inline figures look nice\n",
    "# on a retina macbook. These can be commented out without any\n",
    "# issue and are solely asthetic.\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# UPDATE 2020-12-31 (my preferred font is Avenir...)\n",
    "font = {'family' : 'avenir',\n",
    "    \t'weight' : 'normal'}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# can be installed using \n",
    "# pip install protfasta\n",
    "# for docs see https://protfasta.readthedocs.io/\n",
    "import protfasta\n",
    "\n",
    "# file found locally (fully documented)\n",
    "import disprot_parser\n",
    "\n",
    "# can be installed using \n",
    "# pip install metapredict\n",
    "# for docs see https://metapredict.readthedocs.io/\n",
    "import metapredict as meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7771cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defin CAID prediction files. These files are provided in the `data/` directory but were originally generated as part of the CAID data,\n",
    "# so if you use them please cite this paper [1] and there's no need to cite metapredict!\n",
    "# [1] Critical assessment of protein intrinsic disorder prediction, Nature Methods 2021\n",
    "filenames = ['D001_PyHCA.out', 'D002_Predisorder.out', 'D003_IUPred2A-long.out', 'D004_IUPred2A-short.out', 'D005_IUPred-long.out', 'D006_IUPred-short.out', 'D007_FoldUnfold.out', 'D008_IsUnstruct.out', 'D009_GlobPlot.out', 'D010_DisPredict-2.out', 'D011_DISOPRED-3.1.out', 'D013_fIDPln.out', 'D014_fIDPnn.out', 'D015_VSL2B.out', 'D016_DisEMBL-HL.out', 'D017_DisEMBL-465.out', 'D018_ESpritz-D.out', 'D019_ESpritz-N.out', 'D020_ESpritz-X.out', 'D021_MobiDB-lite.out', 'D022_S2D-1.out', 'D023_S2D-2.out', 'D024_DisoMine.out', 'D025_RawMSA.out', 'D026_AUCpreD.out', 'D027_AUCpreD-np.out', 'D028_SPOT-Disorder1.out', 'D029_SPOT-Disorder2.out', 'D030_SPOT-Disorder-Single.out', 'D031_JRONN.out', 'D032_DFLpred.out', 'D033_DynaMine.out']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4965e1",
   "metadata": {},
   "source": [
    "### Read in DISPROT data\n",
    "This first cell parses through the DISPROT data (defined in `/data` by the files `disprot-2018-*` and `pdb-atleast.fasta` to generate a reliable dataset with which we'll evaluate our predictors on. Notably, this dataset divides each residue in each DISPROT data into one of three classes:\n",
    "\n",
    "* `1` - Disorder - as defined by DISPROT disorder data and not being structured in the PDB data\n",
    "* `0` - Structured - as defined by the PDB data and not being disordered as reproted by the DISPROT data\n",
    "* `-2` - Ambigious - EITHER no data or conflicting data between DISPROT and PDB data\n",
    "\n",
    "Our assessment of the predictors is ONLY done over residues that match residue types 1 and 0 as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36854a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found complete data data for 1041 proteins\n"
     ]
    }
   ],
   "source": [
    "# read in disprot data\n",
    "DISPROT = disprot_parser.parse_disprot()\n",
    "print(f'Found complete data data for {len(DISPROT)} proteins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cb2a7",
   "metadata": {},
   "source": [
    "## Evaluate  predictors\n",
    "The code below evaluates each of the predictors using the DISPROT data defined above. Specifically, for each predictor file we read in the data associated with that predictor, where each predictor has a binary 'disordered' (1) or not disordered (0) score associated with each residue. We simply count the number of residues the predictor gets right vs. the number of residues it gets wrong, which for each predictor are added to the `valids` and `invalids` lists below.\n",
    "\n",
    "Note, as discussed we only evaluate on DISPROT residues where disorder/structure has been unambigiously assigned.\n",
    "\n",
    "Finally, this gives rise to evaluation of each predictor over around 145K amino acids (i.e. ~1000 different protein sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc28e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D001_PyHCA.out\n",
      "D002_Predisorder.out\n",
      "D003_IUPred2A-long.out\n",
      "D004_IUPred2A-short.out\n",
      "D005_IUPred-long.out\n",
      "D006_IUPred-short.out\n",
      "D007_FoldUnfold.out\n",
      "D008_IsUnstruct.out\n",
      "D009_GlobPlot.out\n",
      "D010_DisPredict-2.out\n",
      "D011_DISOPRED-3.1.out\n",
      "D013_fIDPln.out\n",
      "D014_fIDPnn.out\n",
      "D015_VSL2B.out\n",
      "D016_DisEMBL-HL.out\n",
      "D017_DisEMBL-465.out\n",
      "D018_ESpritz-D.out\n",
      "D019_ESpritz-N.out\n",
      "D020_ESpritz-X.out\n",
      "D021_MobiDB-lite.out\n",
      "D022_S2D-1.out\n",
      "D023_S2D-2.out\n",
      "D024_DisoMine.out\n",
      "D025_RawMSA.out\n",
      "D026_AUCpreD.out\n",
      "D027_AUCpreD-np.out\n",
      "D028_SPOT-Disorder1.out\n",
      "D029_SPOT-Disorder2.out\n",
      "D030_SPOT-Disorder-Single.out\n",
      "D031_JRONN.out\n",
      "D032_DFLpred.out\n",
      "D033_DynaMine.out\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# valids and invalids will become lists with residue counts for each predictor\n",
    "valids = []\n",
    "invalids = []\n",
    "\n",
    "# names will become a lists with strings that represent each predictor's name\n",
    "names = []\n",
    "\n",
    "\n",
    "# cycle over each filename in the filenames list defined above\n",
    "for fn in filenames:\n",
    "    print(fn)\n",
    "    \n",
    "    # partse the disprot predictor file (see code i disprot_parser.py for more details), but pred is a dictionary\n",
    "    # where keys are DISPROT IDs and Values are Protein objects, a class we define in disprot_parser.py which is basically\n",
    "    # just a STRUCT for storing structured data.\n",
    "    pred = disprot_parser.parse_file(f'data/{fn}')\n",
    "    \n",
    "    # pull out the name\n",
    "    name = fn.split('_')[1].split('.')[0]\n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    valid_fail = []\n",
    "    \n",
    "    # for each disprot ID found in the predictor we'll ask if we also have DISPROT ID for it, and, if yes,\n",
    "    # we'll then evaluate agreement as described above\n",
    "    for did in pred:\n",
    "        \n",
    "        if did in DISPROT:            \n",
    "            valid_fail.append(disprot_parser.calculate_residue_count(DISPROT[did].disorder_binary, pred[did].disorder_binary))\n",
    "\n",
    "            \n",
    "    # when we get here valid_fail is a list of tuples, where the 1st position ([0]) in the tuple is, for each protein,\n",
    "    # the number of residues the predictor got right and the 2nd position ([1]) is the the number of residues the\n",
    "    # predictor got wrong. We simply sum these up so that for each predictor we have the TOTAL number of correct \n",
    "    # and incorrect residues, which we then add to the valids and invalids lists\n",
    "    valids.append(np.sum(np.array(valid_fail),0)[0])\n",
    "    invalids.append(np.sum(np.array(valid_fail),0)[1])\n",
    "    \n",
    "res_correct_per_100 = 100*(np.array(valids)/np.sum([valids, invalids],0))    \n",
    "with open('accuracy_correct_per_100.tsv','w') as fh:\n",
    "    for i in range(len(filenames)):\n",
    "        fh.write(f'{filenames[i][0:-4]}\\t{res_correct_per_100[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2e101",
   "metadata": {},
   "source": [
    "### metapredict predictions\n",
    "Finally we do the same method of evaluation using metapredict with default settings. Notably we cycle over EVERY DISPROT entry to maximize the number of sequences we evaluate against. \n",
    "\n",
    "For each sequence the function `disprot_parser.extract_binary_disorder()` takes in the DISPROT sequence, predictors disorder, extracts out the IDRs using the `meta.predict_disorder_domains()` function and converts those boundaries to a list of 0s (structured) and 1s (disordered). That list is then compared againt the true data from DISPROT in the same way as all the other predictors were.\n",
    "\n",
    "The `%%time` line at the top (and `print()` at the bottom) are there to provide some performance data on how long it takes to evaliate the full metapredict dataset, which on our test machines takes about 70 seconds (where, the slowest CAID predictor takes ~36 days to do the same evaliation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cdf3e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: length of disorder [24] is <= window_size [24]. This happens when you have a small IDR relative to the minimum IDR size. Updating windowsize to match sequence length.\n",
      "\n",
      "CPU times: user 1min 4s, sys: 4.2 s, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metapredict_valid_fail_default = []\n",
    "\n",
    "\n",
    "for did in DISPROT:    \n",
    "    metapredict_valid_fail_default.append(disprot_parser.calculate_residue_count(DISPROT[did].disorder_binary, \n",
    "                                                             disprot_parser.extract_binary_disorder(DISPROT[did].sequence)))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513367a",
   "metadata": {},
   "source": [
    "### Compute per 100-residue scores\n",
    "Final step allows us to take the fraction of correct residues in all residues and multiply by 100 to get a metric that reports on if we predicted 100 residues to be disordered/ordered how many would we get right. This allows us to convert predictor accuracy into a metric we can intuitively make sense of and, importantly, compare between predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786570cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metapredict correct per 100 = 89.27879366812228\n"
     ]
    }
   ],
   "source": [
    "# compute per 100 correct scores\n",
    "metapredict_per_100 = 100*np.sum(np.array(metapredict_valid_fail_default),0)[0]/np.sum(np.array(metapredict_valid_fail_default))\n",
    "print(f'Metapredict correct per 100 = {metapredict_per_100}')\n",
    "\n",
    "## the code below just orderes the data and builds a new ordered list and names list\n",
    "ordered_data = []\n",
    "for i in range(len(names)):\n",
    "    ordered_data.append([res_correct_per_100[i], names[i]])\n",
    "\n",
    "    \n",
    "ordered_data = sorted(ordered_data, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "ordered_data_scores = []\n",
    "ordered_data_names = []\n",
    "for i in range(len(ordered_data)):\n",
    "    ordered_data_scores.append(ordered_data[i][0])\n",
    "    ordered_data_names.append(ordered_data[i][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(4, 2.6), dpi=150, facecolor='w', edgecolor='k')\n",
    "ax = plt.gca()\n",
    "\n",
    "# this builds ordered data wuth a gap for metapredict (done manually)\n",
    "s1 = ordered_data_scores[0:7]\n",
    "s1.extend([0])\n",
    "s1.extend(ordered_data_scores[7:])\n",
    "\n",
    "n1 = ordered_data_names[0:7]\n",
    "n1.extend(['metapredict'])\n",
    "n1.extend(ordered_data_names[7:])\n",
    "\n",
    "\n",
    "plt.bar(np.arange(1,len(s1)+1), s1, color='k', alpha=0.8)\n",
    "#plt.plot([1,len(filenames)+1],[metapredict_per_100,metapredict_per_100])\n",
    "plt.bar([8],[metapredict_per_100], color='r')\n",
    "plt.ylim([40,100])\n",
    "plt.yticks(fontsize=7)\n",
    "plt.ylabel('Correctly scored residues\\n(per 100)',fontsize=8)\n",
    "plt.xticks(np.arange(1,len(n1)+1), n1, fontsize=5, rotation=90)\n",
    "print(s1[0]-metapredict_per_100)\n",
    "\n",
    "# plot lines for visually comparing\n",
    "plt.plot([1,1],[s1[0],95],'-k', linewidth=0.4)\n",
    "plt.plot([1,8],[95,95],'-k', linewidth=0.4)\n",
    "plt.plot([8,8],[95, metapredict_per_100],'-k', linewidth=0.4)\n",
    "plt.text(1.7,96,'2 residues', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('metapredict_vs_all_accuracy_per_100.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff97f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
