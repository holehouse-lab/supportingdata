{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43935e45-0f74-4625-b8e6-60bf4294e405",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook generates all chainsaw-generated domains for the paper from an input AlphaFold2 derived proteome. Note that this actually generates two versions of the proteome:\n",
    "\n",
    "\n",
    "1. `domains_chainsaw` are the domains where we decompose even internal regions into isolated subdomains. This is the most \"aggressive\" domain decomposition approach.\n",
    "2. `domains_chainsaw_extended` are the domains where we use the broader chainsaw definitions, this is a much less aggressive version, the analysis of which is not in the current version of the manuscript but we included for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d5328-5e5f-46d1-9411-1a14875ca053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import protfasta\n",
    "from finches.utils import folded_domain_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35038c4-fecf-4cf6-92ef-a2041e6b5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file was generated by the chainsaw program as the output\n",
    "with open('../data/chainsaw_domain_definitions.tsv','r') as fh:\n",
    "    content = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56a914-878e-4fdb-81ac-286e937d7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where the alphafold proteome used for input is\n",
    "# the rootdir must be a directory where the ONLY files in that directory are PDB files from AlphaFold2. Importantly the filename structure\n",
    "# should be `AF-<UniProtID>-F1-model_v4.pdb` because this then gets parsed by the code below to map unioprot ID to filename\n",
    "\n",
    "rootdir = '../data/UP000002311_559292_YEAST_v4'\n",
    "outroot = '../data/domains_chainsaw'\n",
    "\n",
    "# build mapping of uniprot IDs to filenames\n",
    "uid2fn = {}\n",
    "for entry in os.listdir(rootdir):    \n",
    "    uid = entry.split('-')[1]\n",
    "    uid2fn[uid] = entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29740c51-04f0-49a5-9929-9441f1d19534",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 0\n",
    "newly_generated = 0\n",
    "found_existing = 0\n",
    "\n",
    "silent_errors = True\n",
    "\n",
    "for idx, line in tqdm(enumerate(content[1:])):\n",
    "    sline = line.strip().split('\\t')\n",
    "\n",
    "    uid = sline[0].split('-')[1]\n",
    "\n",
    "    infile = infile = f'{rootdir}/{uid2fn[uid]}'\n",
    "    outdir = f'{outroot}/{uid}'\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "\n",
    "    boundaries = []\n",
    "    domains = sline[4].split(\"_\")\n",
    "    for d in domains:\n",
    "        sub_domains =  d.split(',')\n",
    "        for sd in sub_domains:\n",
    "            try:\n",
    "                (start,end) = sd.split('-')\n",
    "            except ValueError:\n",
    "                errors = errors + 1\n",
    "                if silent_errors is False:\n",
    "                    print(f'Error unpacking on {line}.\\nSkipping..')\n",
    "                continue\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            if end-start < 10:\n",
    "                pass\n",
    "            else:\n",
    "                boundaries.append([start,end])\n",
    "\n",
    "\n",
    "    for d in boundaries:   \n",
    "\n",
    "        # NB: This +1 offset is actually a tiny error and I'm not sure why it was introduced, but\n",
    "        # the chainsaw number uses a 1-indexing not a zero indexing. For consistency, this is kept\n",
    "        # here but in the future I'd probably reocmmend not offsetting by +1\n",
    "        start = d[0]+1\n",
    "        end = d[1]\n",
    "    \n",
    "        outfile = f'{outdir}/{uid}_{start}_{end}.pdb'\n",
    "        \n",
    "        if not os.path.exists(outfile):\n",
    "            folded_domain_utils.extract_and_write_domains(infile, outfile, start, end)\n",
    "            newly_generated = newly_generated + 1\n",
    "        else:\n",
    "            found_existing = found_existing + 1\n",
    "\n",
    "print('')\n",
    "print(f\"Generated domains for {newly_generated} new proteins\")\n",
    "print(f\"Found domains for {found_existing} existing domains\")\n",
    "print(f\"Had {errors} error lines (skipped)\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f1812-b4c3-40b2-be0c-9126730bf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outroot = '../data/domains_chainsaw_extended'\n",
    "\n",
    "# build mapping of uniprot IDs to filenames\n",
    "uid2fn = {}\n",
    "for entry in os.listdir(rootdir):    \n",
    "    uid = entry.split('-')[1]\n",
    "    uid2fn[uid] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946afb8-ebf4-4205-a819-282be02058a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 0\n",
    "newly_generated = 0\n",
    "found_existing = 0\n",
    "\n",
    "silent_errors = False\n",
    "\n",
    "for idx, line in tqdm(enumerate(content[1:])):\n",
    "    sline = line.strip().split('\\t')\n",
    "\n",
    "    uid = sline[0].split('-')[1]\n",
    "\n",
    "    infile = infile = f'{rootdir}/{uid2fn[uid]}'\n",
    "    outdir = f'{outroot}/{uid}'\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "\n",
    "    boundaries = []\n",
    "    domains = sline[4].split(\"_\")\n",
    "\n",
    "    \n",
    "    for d in domains:\n",
    "        local_domains = d.split(',')\n",
    "        try:\n",
    "            start = int(local_domains[0].split('-')[0])\n",
    "            end = int(local_domains[-1].split('-')[1])\n",
    "        except ValueError:\n",
    "            errors = errors + 1\n",
    "            if silent_errors is False:\n",
    "                print(f'Error unpacking on {line}.\\nSkipping..')\n",
    "            continue\n",
    "        if end-start < 10:\n",
    "            pass\n",
    "        else:\n",
    "            boundaries.append([start,end])\n",
    "\n",
    "    for d in boundaries:  \n",
    "\n",
    "            # NB: This +1 offset is actually a tiny error and I'm not sure why it was introduced, but\n",
    "            # the chainsaw number uses a 1-indexing not a zero indexing. For consistency, this is kept\n",
    "            # here but in the future I'd probably reocmmend not offsetting by +1\n",
    "            start = d[0]+1\n",
    "            end = d[1]\n",
    "        \n",
    "            outfile = f'{outdir}/{uid}_{start}_{end}.pdb'\n",
    "            \n",
    "            if not os.path.exists(outfile):\n",
    "                folded_domain_utils.extract_and_write_domains(infile, outfile, start, end)\n",
    "                newly_generated = newly_generated + 1\n",
    "            else:\n",
    "                found_existing = found_existing + 1\n",
    "\n",
    "print('')\n",
    "print(f\"Generated domains for {newly_generated} new domains\")\n",
    "print(f\"Found domains for {found_existing} existing domains\")\n",
    "print(f\"Had {errors} error lines (skipped)\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
